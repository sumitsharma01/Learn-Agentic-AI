{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d6965",
   "metadata": {},
   "source": [
    "## üìç Day 1: Understanding the Building Blocks ‚Äì From Biological Neurons to Artificial Neurons\n",
    "\n",
    "### üîπ What is AI at its core?\n",
    "Artificial Intelligence (AI) aims to enable machines to mimic human intelligence ‚Äî learning from data, making decisions, recognizing patterns, and solving problems. But how do we replicate \"intelligence\" in a machine?\n",
    "\n",
    "At the heart of many AI systems, especially Deep Learning, lies the neural network, inspired by how our brain works.\n",
    "\n",
    "### üß† Biological Neuron vs Artificial Neuron\n",
    "| **Biological Neuron** | **Artificial Neuron (Perceptron)** |\n",
    "|-----------------------|-----------------------------------|\n",
    "| Receives signals from other neurons | Takes multiple numerical inputs (features) |\n",
    "| Sums the incoming signals | Applies weighted sum of inputs |\n",
    "| Fires or not based on the signal strength | Passes through an activation function |\n",
    "| Sends signal to other neurons | Produces an output (prediction/classification) |\n",
    "\n",
    "#### **Biological Neuron**:\n",
    "- **Dendrites** receive signals\n",
    "- **Cell body** processes them\n",
    "- **Axon** sends the output signal\n",
    "- **Synapse** controls signal strength\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "#### **Artificial Neuron**:\n",
    "- **Inputs** are features (like pixels in an image)\n",
    "- Each input is multiplied by a **weight**\n",
    "- A **bias** is added\n",
    "- **Output** is calculated using an activation function\n",
    "\n",
    "### üî∏ The Perceptron: First Artificial Neuron\n",
    "The perceptron is the simplest type of neural network ‚Äî a single artificial neuron. It models the way a human brain takes inputs and decides based on them.\n",
    "\n",
    "#### üßÆ Mathematical Expression:\n",
    "\\[\n",
    "y = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right)\n",
    "\\]\n",
    "Where:\n",
    "- \\(x_i\\): input features\n",
    "- \\(w_i\\): corresponding weights\n",
    "- \\(b\\): bias term\n",
    "- \\(f\\): activation function\n",
    "- \\(y\\): output (decision/prediction)\n",
    "\n",
    "### ‚ö° What is an Activation Function?\n",
    "An activation function decides whether a neuron should \"fire\" or not ‚Äî just like a threshold in biological neurons.\n",
    "\n",
    "#### In simpler terms:\n",
    "- It's a mathematical function that decides how much signal to pass to the next layer.\n",
    "\n",
    "#### üîß Why do we need it?\n",
    "- Adds **non-linearity** to the model (without it, the model becomes a linear regression).\n",
    "- Helps neural networks learn **complex patterns**.\n",
    "\n",
    "### üß∞ Common Activation Functions:\n",
    "| **Function** | **Graph Shape** | **Use Case** |\n",
    "|--------------|-----------------|--------------|\n",
    "| Sigmoid | S-shaped curve | Binary classification |\n",
    "| ReLU | Zero for negative, linear for positive | Most deep networks use this |\n",
    "| Tanh | Similar to sigmoid, ranges -1 to 1 | Used in some RNNs |\n",
    "| Softmax | Turns outputs into probabilities | Multi-class classification |\n",
    "\n",
    "### üß© Summary\n",
    "| **Concept** | **Description** |\n",
    "|-------------|-----------------|\n",
    "| Neuron | Core unit of computation, inspired by the brain |\n",
    "| Perceptron | Simplest artificial neuron model |\n",
    "| Weights | Determine importance of each input |\n",
    "| Bias | Allows shifting the output |\n",
    "| Activation Function | Decides how output is passed forward |\n",
    "| Output | Final decision or prediction |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f22254",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Simple Perceptron Example: How a Single Neuron Works\n",
    "\n",
    "A perceptron takes inputs, applies weights, adds a bias, then passes the result through an activation function to decide its output.\n",
    "\n",
    "## Step 1: Inputs and Weights\n",
    "\n",
    "Imagine the neuron receives two inputs:\n",
    "\n",
    "- \\( x_1 = 0.5 \\)\n",
    "- \\( x_2 = 0.8 \\)\n",
    "\n",
    "Each input has a weight that shows how important that input is:\n",
    "\n",
    "- \\( w_1 = 0.4 \\)\n",
    "- \\( w_2 = 0.7 \\)\n",
    "\n",
    "## Step 2: Weighted Sum + Bias\n",
    "\n",
    "The neuron calculates a weighted sum of inputs plus a bias term:\n",
    "\n",
    "\\[ z = (w_1 \\times x_1) + (w_2 \\times x_2) + b \\]\n",
    "\n",
    "The bias \\( b \\) allows the neuron to shift the output ‚Äî think of it as an adjustment that helps the neuron decide even if all inputs are zero.\n",
    "\n",
    "Let's say:\n",
    "\n",
    "- \\( b = 0.1 \\)\n",
    "\n",
    "Calculate \\( z \\):\n",
    "\n",
    "\\[ z = (0.4 \\times 0.5) + (0.7 \\times 0.8) + 0.1 = 0.2 + 0.56 + 0.1 = 0.86 \\]\n",
    "\n",
    "## Step 3: Activation Function\n",
    "\n",
    "The neuron applies an activation function to decide the output.\n",
    "\n",
    "A simple example is the step function:\n",
    "\n",
    "\\[ output = \\begin{cases} \n",
    "1 & \\text{if } z \\geq 0 \\\\\n",
    "0 & \\text{if } z < 0 \n",
    "\\end{cases} \\]\n",
    "\n",
    "Since \\( z = 0.86 \\geq 0 \\), the output is **1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be567df",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs\n",
    "x = np.array([0.5, 0.8])\n",
    "\n",
    "# Weights\n",
    "w = np.array([0.4, 0.7])\n",
    "\n",
    "# Bias\n",
    "b = 0.1\n",
    "\n",
    "# Weighted sum\n",
    "z = np.dot(w, x) + b\n",
    "\n",
    "# Activation function (step)\n",
    "def step_function(value):\n",
    "    return 1 if value >= 0 else 0\n",
    "\n",
    "output = step_function(z)\n",
    "\n",
    "print(f\"Weighted sum (z): {z}\")\n",
    "print(f\"Neuron output after activation: {output}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
